{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the following table which details the use of contraception by age of currently married women in El Salvador in 1985.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th colspan=\"3\">Contraceptive Method</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Age</b></td>\n",
    "    <td><b>Ster.</b></td>\n",
    "    <td><b>Other</b></td>\n",
    "    <td><b>None</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>15 - 19</td>\n",
    "    <td>3</td>\n",
    "    <td>61</td>\n",
    "    <td>232</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>20 - 24</td>\n",
    "    <td>80</td>\n",
    "    <td>137</td>\n",
    "    <td>400</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>25 - 29</td>\n",
    "    <td>216</td>\n",
    "    <td>131</td>\n",
    "    <td>301</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>30 - 34</td>\n",
    "    <td>268</td>\n",
    "    <td>76</td>\n",
    "    <td>203</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>35 - 39</td>\n",
    "    <td>197</td>\n",
    "    <td>50</td>\n",
    "    <td>188</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>40 - 44</td>\n",
    "    <td>150</td>\n",
    "    <td>24</td>\n",
    "    <td>164</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>45 - 49</td>\n",
    "    <td>91</td>\n",
    "    <td>10</td>\n",
    "    <td>183</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "#### Let $ t_{i} $ denote an indicator variable which takes on values $ \\{1,2,3\\} $ where 1 is Sterilization, 2 is Other, and 3 is None. Consider the activation function:\n",
    "\n",
    "$$ a_{ij}=\\alpha_{j}+\\beta_{j}x_{i}+\\gamma_{j}x_{i}^{2} $$\n",
    "\n",
    "#### where $ x_{i} $ is the mid-point of the $ i $-th age group, and $ j \\in \\{1,2,3\\} $. Recall that the multinomial logit model is given by\n",
    "\n",
    "$$ p\\left(t_{i}=j|x_{i}\\right)=\\frac{exp\\left(a_{ij}\\right)}{\\sum_{j'}exp\\left(a_{ij'}\\right)} $$\n",
    "\n",
    "#### Implement multinomial logistic regression from scratch (for the underlying optimization you may use modules such as the ones available in $ \\displaystyle{scipy} $) and apply it to the given data. Comment on your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [17, 22, 27, 32, 37, 42, 47]\n",
    "\n",
    "M = np.matrix([[  3,  62, 232],\n",
    "               [ 80, 137, 400],\n",
    "               [216, 131, 301],\n",
    "               [268,  76, 203],\n",
    "               [197,  50, 188],\n",
    "               [150,  24, 164],\n",
    "               [ 91,  10, 183]])\n",
    "\n",
    "def m(i, j):\n",
    "    return M[i - 1, j - 1]\n",
    "\n",
    "def activation(w, i, j):\n",
    "    s_idx = (j - 1) * 3\n",
    "    return w[s_idx] + w[s_idx + 1] * x[i - 1] + w[s_idx + 2] * x[i - 1]**2\n",
    "\n",
    "c_logit_sum = {}\n",
    "\n",
    "def logit(w, i, j):\n",
    "    key = str(w) + '_' + str(i)\n",
    "    if key not in c_logit_sum:\n",
    "        c_logit_sum[key] = np.exp(activation(w, i, 1)) + np.exp(activation(w, i, 2)) + np.exp(activation(w, i, 3))\n",
    "    sum = c_logit_sum[key]\n",
    "    return np.exp(activation(w, i, j)) / sum\n",
    "\n",
    "def error(w, i):\n",
    "    return - m(i, 1) * np.log(logit(w, i, 1)) - m(i, 2) * np.log(logit(w, i, 2)) - m(i, 3) * np.log(logit(w, i, 3))\n",
    "\n",
    "w0 = [100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
    "# w_ml = []\n",
    "# for s in range(len(x)):\n",
    "#     res = minimize(neg_likelihood, w0, args=(s + 1, ), method='COBYLA')\n",
    "#     if (res.success):\n",
    "#         w_ml.append(res.x)\n",
    "\n",
    "# print(w_ml)\n",
    "\n",
    "res = minimize(error, w0, args=(4, ), method='COBYLA')\n",
    "if (res.success):\n",
    "    print(res.x)\n",
    "else:\n",
    "    print(res)\n",
    "\n",
    "\n",
    "# w1_ml = [-4.30243814e+00, -7.60004802e-04,  1.21589921e-07,\n",
    "#         -1.29240916e+00,  3.29655268e-04,  1.35854539e-08,\n",
    "#          3.28688361e-02, -3.78431790e-07, -2.09425802e-07]\n",
    "\n",
    "# print(logit(w_ml, 5, 1))\n",
    "# print(logit(w_ml, 5, 2))\n",
    "# print(logit(w_ml, 5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the Enron-spam dataset from http://www.aueb.gr/users/ion/data/enron-spam/. Use the pre-processed datasets Enron1, . . . , Enron5 as training data and Enron6 as test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement the Naive Bayes algorithm that we discussed in the class (a good in-depth reference is http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf). Remember to perform all calculations on the log scale to prevent underow.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Report the accuracy on the test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How do you account for di\u000b",
    "erent prior probabilities for spam and ham?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Does the performance of the classi\f",
    "er change when you do add one Laplace smoothing?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What are the most discriminative words as per the naive Bayes classifer?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work on the same dataset as the above problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Implement the binary logistic regression algorithm that we discussed in the class. You may use any optimizer of your choice including optimization modules from $ \\displaystyle{scipy} $.**\n",
    " - **Report accuracy on test set.**\n",
    " - **How do you account for different prior probabilities for spam and ham?**\n",
    " - **What are the most discriminative words as per the logistic regression classifer?**\n",
    "\n",
    "- **Implement the Bayesian logistic regression algorithm that we discussed in the class.**\n",
    " - **Report accuracy on test set.**\n",
    " - **How does the accuracy change when the strength of the prior changes?**\n",
    "\n",
    "#### Comment on the differences and similarities between the three classifers that you implemented to solve the spam detection problem (naive bayes, binary logistic regression and bayesian logistic regression)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
